<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>Real-Time AI Tennis Coach</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            overscroll-behavior-y: contain; /* Prevents pull-to-refresh on mobile */
        }
        .video-container {
            position: relative;
            width: 100%;
            max-width: 800px;
            margin: auto;
            border-radius: 0.75rem;
            overflow: hidden;
            box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
            background-color: #000;
        }
        #video {
            display: block;
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        #status-overlay {
            position: absolute;
            bottom: 0;
            left: 0;
            right: 0;
            background: rgba(0, 0, 0, 0.6);
            color: white;
            padding: 0.75rem 1rem;
            text-align: center;
            font-weight: 500;
            transition: opacity 0.3s ease-in-out;
        }
        .pulsing {
            animation: pulse 2s cubic-bezier(0.4, 0, 0.6, 1) infinite;
        }
        @keyframes pulse {
            0%, 100% {
                opacity: 1;
            }
            50% {
                opacity: 0.7;
            }
        }
        #modal-backdrop {
            transition: opacity 0.3s ease-in-out;
        }
        #modal-content {
            transition: transform 0.3s ease-in-out;
        }
    </style>
</head>
<body class="bg-gray-100 text-gray-800 flex flex-col items-center justify-center min-h-screen p-4">

    <div class="w-full max-w-4xl text-center mb-6">
        <h1 class="text-4xl font-bold text-gray-900">AI Tennis Forehand Coach</h1>
        <p class="text-lg text-gray-600 mt-2">Get real-time feedback on your form. Powered by Gemini.</p>
    </div>

    <div id="video-container" class="video-container">
        <video id="video" playsinline autoplay></video>
        <canvas id="canvas" class="hidden"></canvas>
        <div id="status-overlay" class="opacity-0">
            <p id="status-text">Initializing...</p>
        </div>
    </div>

    <div class="mt-6 flex flex-col items-center space-y-4 w-full max-w-4xl">
        <div class="w-full max-w-md mb-2 bg-white p-4 rounded-lg shadow-md">
            <label for="api-key-input" class="block text-sm font-medium text-gray-700 mb-1">Enter Your Gemini API Key:</label>
            <div class="flex space-x-2">
                <input type="password" id="api-key-input" class="flex-grow p-2 border border-gray-300 rounded-lg focus:ring-blue-500 focus:border-blue-500" placeholder="Paste your API key here">
                <button id="save-key-button" class="px-4 py-2 bg-blue-600 text-white font-semibold rounded-lg hover:bg-blue-700 focus:outline-none focus:ring-2 focus:ring-blue-500">Save Key</button>
            </div>
            <p id="api-key-status" class="text-xs text-gray-500 mt-2">You need a free Gemini API key from <a href="https://aistudio.google.com/apikey" target="_blank" class="text-blue-600 hover:underline">Google AI Studio</a> to use this app.</p>
        </div>
        
        <div class="flex items-center space-x-4">
             <button id="toggle-button" class="px-8 py-4 bg-blue-600 text-white font-bold rounded-lg shadow-lg hover:bg-blue-700 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-opacity-50 transition-transform transform hover:scale-105 disabled:bg-gray-400 disabled:cursor-not-allowed disabled:scale-100">
                Start Coaching
            </button>
            <button id="flip-camera-button" class="hidden p-4 bg-gray-200 text-gray-700 rounded-full shadow-lg hover:bg-gray-300 focus:outline-none focus:ring-2 focus:ring-gray-400">
                <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
                  <path stroke-linecap="round" stroke-linejoin="round" d="M15 12a3 3 0 11-6 0 3 3 0 016 0z" />
                  <path stroke-linecap="round" stroke-linejoin="round" d="M2.458 12C3.732 7.943 7.523 5 12 5c4.478 0 8.268 2.943 9.542 7-1.274 4.057-5.064 7-9.542 7-4.477 0-8.268-2.943-9.542-7z" />
                  <path stroke-linecap="round" stroke-linejoin="round" d="M19 9l-2 2-2-2m-2 8l2-2 2 2"/>
                </svg>
            </button>
        </div>


         <button id="summary-button" class="hidden px-8 py-4 bg-purple-500 text-white font-bold rounded-lg shadow-lg hover:bg-purple-600 focus:outline-none focus:ring-2 focus:ring-purple-500 focus:ring-opacity-50 transition-transform transform hover:scale-105">
            ‚ú® Summarize My Session
        </button>
        <div id="feedback-container" class="w-full bg-white p-4 rounded-lg shadow-md min-h-[80px] flex items-center justify-center">
            <p id="feedback-text" class="text-gray-500 text-center">Your coaching advice will appear here.</p>
        </div>
    </div>

    <!-- Modal Structure -->
    <div id="modal" class="hidden fixed inset-0 z-50 flex items-center justify-center p-4">
        <div id="modal-backdrop" class="fixed inset-0 bg-black bg-opacity-50"></div>
        <div id="modal-content" class="bg-white rounded-lg shadow-2xl w-full max-w-2xl max-h-[80vh] overflow-y-auto p-6 z-10 transform scale-95">
            <div class="flex justify-between items-center border-b pb-3 mb-4">
                <h2 id="modal-title" class="text-2xl font-bold"></h2>
                <button id="modal-close" class="text-gray-500 hover:text-gray-800 text-3xl">&times;</button>
            </div>
            <div id="modal-body" class="prose max-w-none text-gray-700 whitespace-pre-wrap"></div>
        </div>
    </div>


    <script>
        // --- DOM Elements ---
        const videoContainer = document.getElementById('video-container');
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const toggleButton = document.getElementById('toggle-button');
        const summaryButton = document.getElementById('summary-button');
        const flipCameraButton = document.getElementById('flip-camera-button');
        const statusOverlay = document.getElementById('status-overlay');
        const statusText = document.getElementById('status-text');
        const feedbackText = document.getElementById('feedback-text');
        const modal = document.getElementById('modal');
        const modalBackdrop = document.getElementById('modal-backdrop');
        const modalContent = document.getElementById('modal-content');
        const modalTitle = document.getElementById('modal-title');
        const modalBody = document.getElementById('modal-body');
        const modalClose = document.getElementById('modal-close');
        const apiKeyInput = document.getElementById('api-key-input');
        const saveKeyButton = document.getElementById('save-key-button');
        const apiKeyStatus = document.getElementById('api-key-status');

        // --- State and Configuration ---
        let stream;
        let coachingTimeout = null;
        let isCoaching = false;
        let sessionFeedbackLog = [];
        let userApiKey = '';
        let hasMultipleCameras = false;
        let currentFacingMode = 'environment';
        let audioContext;
        let gainNode;
        const CAPTURE_INTERVAL = 10000;

        // --- Gemini API Configuration ---
        const TEXT_API_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent`;
        const TTS_API_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent`;

        const VISION_PROMPT = `You are an expert tennis coach analyzing a tennis player's form from a single image. Your analysis should be based on the 8 phases of a world-class stroke: Split Step, Positioning, Unit Turn, Back Swing, Acceleration, Contact, Follow Through, and Recovery. After analyzing all 8 phases, your task is to identify the single most critical area for improvement. Your entire output MUST be a single, concise sentence that summarizes this one key piece of advice. This advice must be a maximum of 2 sentences and under 30 words. For example: 'Focus on extending your wrist more during the backswing for better racket lag.' or 'Your unit turn looks great, but try to get your contact point further in front.' If you cannot identify any clear flaw or if the player's form looks good, do not return any text. Do not provide the full 8-point breakdown in your response.`;

        // --- Event Listeners ---
        toggleButton.addEventListener('click', toggleCoaching);
        flipCameraButton.addEventListener('click', flipCamera);
        summaryButton.addEventListener('click', summarizeSession);
        modalClose.addEventListener('click', closeModal);
        modalBackdrop.addEventListener('click', closeModal);
        saveKeyButton.addEventListener('click', saveApiKey);
        window.addEventListener('resize', handleResize);
        document.addEventListener('DOMContentLoaded', initializeApp);


        // --- Core Functions ---
        
        function initializeApp() {
            const savedKey = localStorage.getItem('gemini-api-key');
            if (savedKey) {
                userApiKey = savedKey;
                apiKeyInput.value = savedKey;
                apiKeyStatus.textContent = 'API Key loaded from your browser.';
                apiKeyStatus.classList.add('text-green-600');
            }
            checkApiKeyState();
            handleResize(); // Set initial size
        }
        
        function handleResize() {
            if (window.innerHeight > window.innerWidth) {
                videoContainer.style.aspectRatio = '9 / 16';
            } else {
                videoContainer.style.aspectRatio = '16 / 9';
            }
        }

        function saveApiKey() {
            const key = apiKeyInput.value.trim();
            if (key) {
                localStorage.setItem('gemini-api-key', key);
                userApiKey = key;
                apiKeyStatus.textContent = 'API Key saved successfully!';
                apiKeyStatus.classList.add('text-green-600');
                apiKeyStatus.classList.remove('text-red-600');
                checkApiKeyState();
            } else {
                apiKeyStatus.textContent = 'Please enter a valid API key.';
                apiKeyStatus.classList.add('text-red-600');
                apiKeyStatus.classList.remove('text-green-600');
            }
        }
        
        function checkApiKeyState() {
            const hasKey = !!userApiKey;
            toggleButton.disabled = !hasKey;
            if (!hasKey) {
                feedbackText.textContent = 'Please enter and save your Gemini API key to begin.';
            } else if (!isCoaching) {
                feedbackText.textContent = 'Your coaching advice will appear here.';
            }
        }
        
        async function toggleCoaching() {
            if (isCoaching) {
                stopCoaching();
            } else {
                await startCoaching();
            }
        }

        async function startCamera() {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
            }
            // Request both video and audio
            const constraints = { video: { facingMode: currentFacingMode }, audio: true };
            try {
                updateStatus('Requesting camera & mic access...', true);
                stream = await navigator.mediaDevices.getUserMedia(constraints);
                
                // Set video source but keep it muted in the HTML element
                video.srcObject = stream;
                video.muted = true; 
                await video.play();

                // Web Audio API setup for silent mic input
                if (!audioContext) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    const microphoneSource = audioContext.createMediaStreamSource(stream);
                    gainNode = audioContext.createGain();
                    gainNode.gain.setValueAtTime(0, audioContext.currentTime); // Mute microphone
                    microphoneSource.connect(gainNode);
                    gainNode.connect(audioContext.destination);
                }

                video.style.transform = currentFacingMode === 'user' ? 'scaleX(-1)' : 'scaleX(1)';
                updateStatus('Camera started.', true);
                if (!hasMultipleCameras) {
                    const devices = await navigator.mediaDevices.enumerateDevices();
                    hasMultipleCameras = devices.filter(d => d.kind === 'videoinput').length > 1;
                }
                if (hasMultipleCameras) {
                    flipCameraButton.classList.remove('hidden');
                }
            } catch (error) {
                console.error('Error accessing camera/mic:', error);
                updateStatus('Camera/mic access denied. Please enable permissions.', false, true);
                throw error;
            }
        }

        async function flipCamera() {
            currentFacingMode = currentFacingMode === 'environment' ? 'user' : 'environment';
            await startCamera();
        }
        
        async function startCoaching() {
            isCoaching = true;
            sessionFeedbackLog = [];
            summaryButton.classList.add('hidden');
            toggleButton.textContent = 'Stop Coaching';
            toggleButton.classList.replace('bg-blue-600', 'bg-red-600');
            toggleButton.classList.replace('hover:bg-blue-700', 'hover:bg-red-700');
            feedbackText.textContent = "Let's begin! I'll provide feedback shortly.";
            try {
                await startCamera();
                updateStatus('Coaching started. Capturing first clip...', true, false, true);
                coachingLoop(); 
            } catch (error) {
                stopCoaching();
            }
        }

        function stopCoaching() {
            isCoaching = false;
            if (coachingTimeout) clearTimeout(coachingTimeout);
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                stream = null;
                video.srcObject = null;
            }
            if (audioContext && audioContext.state !== 'closed') {
                audioContext.close().then(() => audioContext = null);
            }
            if(sessionFeedbackLog.length > 0) summaryButton.classList.remove('hidden');
            toggleButton.textContent = 'Start Coaching';
            toggleButton.classList.replace('bg-red-600', 'bg-blue-600');
            toggleButton.classList.replace('hover:bg-red-700', 'hover:bg-blue-700');
            flipCameraButton.classList.add('hidden');
            updateStatus('Coaching stopped.', false);
            checkApiKeyState();
        }

        async function coachingLoop() {
            if (!isCoaching) return;
            try {
                updateStatus('Capturing your form...', true, false, true);
                const base64Image = captureFrame();
                if (base64Image) {
                    updateStatus('Analyzing your form with Gemini...', true, false, true);
                    const analysisText = await analyzeFrame(base64Image);
                    if (analysisText) {
                        feedbackText.textContent = analysisText;
                        sessionFeedbackLog.push(analysisText);
                        await speakFeedback(analysisText);
                    } else {
                         updateStatus(`Looking good! Next analysis in ${CAPTURE_INTERVAL / 1000}s.`, true);
                    }
                } else {
                    console.warn("Failed to capture frame, will retry.");
                    updateStatus('Waiting for camera...', true, false, true);
                }
            } catch (error) {
                console.error("Error in coaching loop:", error);
                updateStatus('An error occurred. Retrying soon.', true, true);
                feedbackText.textContent = "Sorry, I couldn't analyze that shot.";
            } finally {
                if (isCoaching) coachingTimeout = setTimeout(coachingLoop, CAPTURE_INTERVAL);
            }
        }
        
        async function summarizeSession() {
            if (sessionFeedbackLog.length === 0) {
                openModal("No feedback was recorded in this session.", "üìù Session Summary");
                return;
            }
            const feedbackString = sessionFeedbackLog.join('. ');
            const prompt = `You are an encouraging tennis coach. Based on the following list of feedback given to a player during a practice session, write a brief summary. First, identify the most common area for improvement. Then, provide a short, positive message and one concrete tip for their next session. Use markdown for structure (e.g., ### Key Focus Area, ### Coach's Note). Feedback list: "${feedbackString}"`;
            openModal("Analyzing your session...", "üìù Session Summary");
             try {
                const summaryText = await generateText(prompt);
                updateModalBody(summaryText);
            } catch (error) {
                console.error("Error summarizing session:", error);
                updateModalBody("Sorry, I couldn't generate a summary right now.");
            }
        }
        
        async function generateText(prompt) {
            const payload = { contents: [{ parts: [{ text: prompt }] }] };
            const response = await fetch(`${TEXT_API_URL}?key=${userApiKey}`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            });
            if (!response.ok) throw new Error(`API Error: ${response.status} ${response.statusText}`);
            const result = await response.json();
            return result.candidates?.[0]?.content?.parts?.[0]?.text || "No response generated.";
        }

        function captureFrame() {
            if (!stream || !video.srcObject || video.readyState < 2) return null;
            const videoTrack = stream.getVideoTracks()[0];
            const settings = videoTrack.getSettings();
            canvas.width = settings.width;
            canvas.height = settings.height;
            const context = canvas.getContext('2d');
            if (currentFacingMode === 'user') {
                context.scale(-1, 1);
                context.drawImage(video, -canvas.width, 0, canvas.width, canvas.height);
            } else {
                context.drawImage(video, 0, 0, canvas.width, canvas.height);
            }
            return canvas.toDataURL('image/jpeg', 0.8).split(',')[1];
        }

        async function analyzeFrame(base64ImageData) {
            const payload = {
                contents: [{ parts: [{ text: VISION_PROMPT }, { inlineData: { mimeType: "image/jpeg", data: base64ImageData } }] }],
            };
            const response = await fetch(`${TEXT_API_URL}?key=${userApiKey}`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            });
            if (!response.ok) throw new Error(`API Error: ${response.status} ${response.statusText}`);
            const result = await response.json();
            return result.candidates?.[0]?.content?.parts?.[0]?.text || null;
        }
        
        function speakFeedback(text) {
            if (!text || !audioContext) return Promise.resolve();
            updateStatus('Playing feedback...', true);
            return new Promise(async (resolve, reject) => {
                const payload = {
                    contents: [{ parts: [{ text: text }] }],
                    generationConfig: { 
                        responseModalities: ["AUDIO"], 
                        speechConfig: { voiceConfig: { prebuiltVoiceConfig: { voiceName: "Kore" } } } 
                    }
                };
                try {
                    const response = await fetch(`${TTS_API_URL}?key=${userApiKey}`, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify(payload) });
                    if (!response.ok) throw new Error(`TTS API Error: ${response.status} ${response.statusText}`);
                    
                    const result = await response.json();
                    const audioData = result.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
                    const mimeType = result.candidates?.[0]?.content?.parts?.[0]?.inlineData?.mimeType;

                    if (audioData && mimeType?.startsWith("audio/")) {
                        const sampleRateMatch = mimeType.match(/rate=(\d+)/);
                        if (!sampleRateMatch) throw new Error("Sample rate not found");
                        
                        const sampleRate = parseInt(sampleRateMatch[1], 10);
                        const pcmData = base64ToArrayBuffer(audioData);
                        const pcm16 = new Int16Array(pcmData);
                        const wavBlob = pcmToWav(pcm16, 1, sampleRate);
                        const arrayBuffer = await wavBlob.arrayBuffer();

                        audioContext.decodeAudioData(arrayBuffer, 
                            (buffer) => {
                                const source = audioContext.createBufferSource();
                                source.buffer = buffer;
                                source.connect(audioContext.destination);
                                source.onended = () => {
                                    if(isCoaching) updateStatus(`Next analysis in ${CAPTURE_INTERVAL / 1000}s.`, true);
                                    resolve();
                                };
                                source.start(0);
                            }, 
                            (error) => {
                                console.error('Error decoding audio data:', error);
                                reject(error);
                            }
                        );
                    } else {
                        throw new Error("No audio data received");
                    }
                } catch (error) {
                    console.error("Failed to speak feedback:", error);
                    updateStatus('Error playing audio.', true, true);
                    reject(error);
                }
            });
        }
        
        function openModal(bodyText, titleText) {
            modalTitle.textContent = titleText;
            modalBody.textContent = bodyText;
            modal.classList.remove('hidden');
            setTimeout(() => {
                modalBackdrop.classList.remove('opacity-0');
                modalContent.classList.remove('scale-95');
            }, 10);
        }

        function updateModalBody(newText) {
             modalBody.textContent = newText;
        }

        function closeModal() {
            modalBackdrop.classList.add('opacity-0');
            modalContent.classList.add('scale-95');
            setTimeout(() => {
                modal.classList.add('hidden');
            }, 300);
        }

        function updateStatus(message, show, isError = false, isPulsing = false) {
            statusText.textContent = message;
            statusOverlay.classList.toggle('opacity-0', !show);
            statusOverlay.classList.toggle('bg-red-600', isError);
            statusOverlay.classList.toggle('bg-opacity-60', !isError);
            statusOverlay.classList.toggle('pulsing', isPulsing);
        }

        function base64ToArrayBuffer(base64) {
            const binaryString = window.atob(base64);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer;
        }

        function pcmToWav(pcmData, numChannels, sampleRate) {
            const buffer = new ArrayBuffer(44 + pcmData.length * 2);
            const view = new DataView(buffer);
            const bitsPerSample = 16;
            const blockAlign = numChannels * bitsPerSample / 8;
            const byteRate = sampleRate * blockAlign;
            writeString(view, 0, 'RIFF');
            view.setUint32(4, 36 + pcmData.length * 2, true);
            writeString(view, 8, 'WAVE');
            writeString(view, 12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, numChannels, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, byteRate, true);
            view.setUint16(32, blockAlign, true);
            view.setUint16(34, bitsPerSample, true);
            writeString(view, 36, 'data');
            view.setUint32(40, pcmData.length * 2, true);
            for (let i = 0; i < pcmData.length; i++) {
                view.setInt16(44 + i * 2, pcmData[i], true);
            }
            return new Blob([view], { type: 'audio/wav' });
        }

        function writeString(view, offset, string) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }
    </script>
</body>
</html>

